  Without tools to read them, annotations are hardly more useful than comments. An important part of the process of using annotations is to create and use annotation processors. Java SE5 provides extensions to the reflection API to help you create these tools. It also provides an external tool called apt to help you parse Java source code with annotations. 
  Here is a very simple annotation processor that reads the annotated PasswordUtils class and uses reflection to look for @UseCase tags. Given a list of id values, it lists the use cases it finds and reports any that are missing: 
  This uses both the reflection method getDeclaredMethods( ) and the method getAnnotation( ), which comes from the AnnotatedElement interface (classes like Class, Method and Field all implement this interface). This method returns the annotation object of the specified type, in this case "UseCase." If there are no annotations of that particular type on the annotated method, a null value is returned. The element values are extracted by calling id( ) and description( ). Remember that no description was specified in the annotation for the encryptPassword( ) method, so the processor above finds the default value "no description" when it calls the description( ) method on that particular annotation. 
Annotation elements
  The @UseCase tag defined in UseCase.java contains the int element id and String element description. Here is a list of the allowed types for annotation elements: 
  • All primitives (int, float, boolean etc.)  • String 
  • Class  • Enums 
  • Annotations  • Arrays of any of the above 
  The compiler will report an error if you try to use any other types. Note that you are not allowed to use any of the wrapper classes, but because of autoboxing this isn’t really a limitation. You can also have elements that are themselves annotations. As you will see a bit later, nested annotations can be very helpful. 
Default value constraints
  The compiler is quite picky about default element values. No element can have an unspecified value. This means that elements must either have default values or values provided by the class that uses the annotation. 
  There is another restriction, which is that none of the non-primitive type elements are allowed to take null as a value, either when declared in the source code or when defined as a default value in the annotation interface. This makes it hard to write a processor that acts on the presence or absence of an element, because every element is effectively present in every annotation declaration. You can get around this by checking for specific values, like empty strings or negative values: 
  This is a typical idiom in annotation definitions. 
Generating external files
  Annotations are especially useful when working with frameworks that require some sort of additional information to accompany your source code. Technologies like Enterprise JavaBeans (prior to EJB3) require numerous interfaces and deployment descriptors which are "boilerplate" code, defined in the same way for every bean. Web services, custom tag libraries and object/relational mapping tools like Toplink and Hibernate often require XML descriptors that are external to the code. After defining a Java class, the programmer must undergo the tedium of respecifying information like the name, package and so on— information that already exists in the original class. Whenever you use an external descriptor file, you end up with two separate sources of information about a class, which usually leads to code synchronization problems. This also requires that programmers working on the project must know about editing the descriptor as well as how to write Java programs. 
  Suppose you want to provide basic object/relational mapping functionality to automate the creation of a database table in order to store a JavaBean. You could use an XML descriptor file to specify the name of the class, each member, and information about its database mapping. Using annotations, however, you can keep all of the information in the JavaBean source file. To do this, you need annotations to define the name of the database table associated with the bean, the columns, and the SQL types to map to the bean’s properties. 
  Here is an annotation for a bean that tells the annotation processor that it should create a database table: 
  Each ElementType that you specify in the @Target annotation is a restriction that tells the compiler that your annotation can only be applied to that particular type. You can specify a single value of the enum ElementType, or you can specify a comma-separated list of any combination of values. If you want to apply the annotation to any ElementType, you can leave out the @Target annotation altogether, although this is uncommon. 
  Note that @DBTable has a name( ) element so that the annotation can supply a name for the database table that the processor will create. 
  Here are the annotations for the JavaBean fields: 
  The @Constraints annotation allows the processor to extract the metadata about the database table. This represents a small subset of the constraints generally offered by databases, but it gives you the general idea. The elements primaryKey( ), allowNull( ) and unique( ) are given sensible default values so that in most cases a user of the annotation won’t have to type too much. 
  The other two (@interfaces define SQL types. Again, for this framework to be more useful, you need to define an annotation for each additional SQL type. Here, two types will be enough. 
  These types each have a name( ) element and a constraints( ) element. The latter makes use of the nested annotation feature to embed the information about the column type’s database constraints. Note that the default value for the contraints( ) element is @Constraints. Since there are no element values specified in parentheses after this annotation type, the default value of constraints( ) is actually an @Constraints annotation with its own default values set. To make a nested @Constraints annotation with uniqueness set to true by default, you can define its element like this: 
  Here is a simple bean that uses these annotations: 
  The @DBTable class annotation is given the value "MEMBER", which will be used as the table name. The bean properties, firstName and lastName, are both annotated with @SQLStrings and have element values of 30 and 50, respectively. These annotations are interesting for two reasons: First, they use the default value on the nested (@Constraints annotation, and second, they use a shortcut feature. If you define an element on an annotation with the name value, then as long as it is the only element type specified you don’t need to use the name-value pair syntax; you can just specify the value in parentheses. 
  This can be applied to any of the legal element types. Of course this limits you to naming your element "value" but in the case above, it does allow for the semantically meaningful and easy- to-read annotation specification: 
  @SQLString(30)  The processor will use this value to set the size of the SQL column that it will create. 
  As neat as the default-value syntax is, it quickly becomes complex. Look at the annotation on the field handle. This has an @SQLString annotation, but it also needs to be a primary key on the database, so the element type primaryKey must be set on the nested @Constraint annotation. This is where it gets messy. You are now forced to use the rather long-winded namevalue pair form for this nested annotation, respecifying the element name and the @interface name. But because the specially named element value is no longer the only element value being specified, you can’t use the shortcut form. As you can see, the result is not pretty. 
  Alternative solutions  There are other ways of creating annotations for this task. You could, for example, have a single annotation class called @TableColumn with an enum element which defines values like STRING, INTEGER, FLOAT, etc. This eliminates the need for an @interface for each SQL type, but makes it impossible to qualify your types with additional elements like size, or precision, which is probably more useful. 
  You could also use a String element to describe the actual SQL type, e.g., "VARCHAR(30)" or "INTEGER". This does allow you to qualify the types, but it ties up the mapping from Java type to SQL type in your code, which is not good design. You don’t want to have to recompile classes if you change databases; it would be more elegant just to tell your annotation processor that you are using a different "flavor" of SQL, and it let it take that into account when processing the annotations. 
  A third workable solution is to use two annotation types together, @Constraints and the relevant SQL type (for example, @SQLInteger), to annotate the desired field. This is slightly messy but the compiler allows as many different annotations as you like on an annotation target. Note that when using multiple annotations, you cannot use the same annotation twice. 
Annotations don’t support inheritance
  You cannot use the extends keyword with @interfaces. This is a pity, because an elegant solution would have been to define an annotation @TableColumn, as suggested above, with a nested annotation of type @SQLType. That way, you could inherit all your SQL types, like @SQLInteger and @SQLString, from @SQLType. This would reduce typing and neaten the syntax. There doesn’t seem to be any suggestion of annotations supporting inheritance in future releases, so the examples above seem to be the best you can do under the circumstances. 
Implementing the processor
  Here is an example of an annotation processor which reads in a class file, checks for its database annotations and generates the SQL command for making the database: 
  The main( ) method cycles through each of the class names on the command line. Each class is loaded using forName( ) and checked to see if it has the @DBTable annotation on it with getAnnotation(DBTable.class). If it does, then the table name is found and stored. All of the fields in the class are then loaded and checked using getDeclaredAnnotations( ). This method returns an array of all of the defined annotations for a particular method. The instanceof operator is used to determine if these annotations are of type @SQLInteger and @SQLString, and in each case the relevant String fragment is then created with the name of the table column. Note that because there is no inheritance of annotation interfaces, using getDeclaredAnnotations( ) is the only way you can approximate polymorphic behavior. 
  The nested @Constraint annotation is passed to the getConstraints( ) which builds up a String containing the SQL constraints. 
  It is worth mentioning that the technique shown above is a somewhat naive way of defining an object/relational mapping. Having an annotation of type @DBTable which takes the table name as a parameter forces you to recompile your Java code if you want to change the table name. This might not be desirable. There are many available frameworks for mapping objects to relational databases, and more and more of them are making use of annotations. 
  Exercise 1: (2) Implement more SQL types in the database example. 
  Project3 Modify the database example so that it connects and interacts with a real database using JDBC. 
  Project: Modify the database example so that it creates conformant XML files rather than writing SQL code. 
  guide. 
