  By now you should understand that although there are only four fundamental container types—Map, List, Set, and Queue—there is more than one implementation of each interface. If you need to use the functionality offered by a particular interface, how do you decide which implementation to use? 
  Each different implementation has its own features, strengths, and weaknesses. For example, you can see in the figure at the beginning of this chapter that the "feature" of Hashtable, Vector, and Stack is that they are legacy classes, so that old code doesn’t break (it’s best if you don’t use those for new code). 
  The different types of Queues in the Java library are differentiated only by the way they accept and produce values (you’ll see the importance of these in the Concurrency chapter). 
  The distinction between containers often comes down to what they are "backed by"—that is, the data structures that physically implement the desired interface. For example, because ArrayList and LinkedList implement the List interface, the basic List operations are the    same regardless of which one you use. However, ArrayList is backed by an array, and LinkedList is implemented in the usual way for a doubly linked list, as individual objects each containing data along with references to the previous and next elements in the list. Because of this, if you want to do many insertions and removals in the middle of a list, a LinkedList is the appropriate choice. (LinkedList also has additional functionality that is established in AbstractSequentialList.) If not, an ArrayList is typically faster. 
  As another example, a Set can be implemented as either a TreeSet, a HashSet, or a LinkedHashSet.9 Each one has different behaviors: HashSet is for typical use and provides raw speed on lookup, LinkedHashSet keeps pairs in insertion order, and TreeSet is backed by TreeMap and is designed to produce a constantly sorted set. You choose the implementation based on the behavior you need. 
  Sometimes different implementations of a particular container will have operations in common, but the performance of those operations will be different. In this case, you’ll choose between implementations based on how often you use a particular operation, and how fast you need it to be. For cases like this, one way to look at the differences between container implementations is with a performance test. 
A performance test framework
  To prevent code duplication and to provide consistency among tests, I’ve put the basic functionality of the test process into a framework. The following code establishes a base class from which you create a list of anonymous inner classes, one for each different test. Each of these inner classes is called as part of the testing process. This approach allows you to easily add and remove new kinds of tests. 
  This is another example of the Template Method design pattern. Although you follow the typical Template Method approach of overriding the method Test.test( ) for each particular 10 test, in this case the core code (that doesn’t change) is in a separate Tester class. The type of container under test is the generic parameter C: 
  Each Test object stores the name of that test. When you call the test( ) method, it must be given the container to be tested along with a "messenger" or "data transfer object" that holds the various parameters for that particular test. The parameters include size, indicating the number of elements in the container, and loops, which controls the number of iterations for that test. These parameters may or may not be used in every test. 
  Each container will undergo a sequence of calls to test( ), each with a different TestParam, so TestParam also contains static array( ) methods that make it easy to create arrays of TestParam objects. The first version of array( ) takes a variable argument list containing alternating size and loops values, and the second version takes the same kind of list except   additional specialized implementations of various container interfaces, this section attempts to look at the more general cases. 
  that the values are inside Strings—this way, it can be used to parse commandline arguments: 
  To use the framework, you pass the container to be tested along with a List of Test objects to a Tester.run( ) method (these are overloaded generic convenience methods which reduce the amount of typing necessary to use them). Tester.run( ) calls the appropriate overloaded constructor, then calls timedTest( ), which executes each test in the list for that container. timedTest( ) repeats each test for each of the TestParam objects in paramList. Because paramList is initialized from the static defaultParams array, you can change the paramList for all tests by reassigning defaultParams, or you can change the paramList for one test by passing in a custom paramList for that test: 
  The stringField( ) and numberField( ) methods produce formatting strings for outputting the results. The standard width for formatting can be changed by modifying the    static fieldWidth value. The displayHeader( ) method formats and prints the header information for each test. 
  If you need to perform special initialization, override the initialize( ) method. This produces an initialized container object of the appropriate size—you can either modify the existing container object or create a new one. You can see in test( ) that the result is captured in a local reference called kontainer, which allows you to replace the stored member container with a completely different initialized container. 
  The return value of each Test.test( ) method must be the number of operations performed by that test, which is used to calculate the number of nanoseconds required for each operation. You should be aware that System.nanoTime( ) typically produces values with a granularity that is greater than one (and this granularity will vary with machines and operating systems), and this will produce a certain amount of rattle in the results. 
  The results may vary from machine to machine; these tests are only intended to compare the performance of the different containers. 
Choosing between Lists
  Here is a performance test for the most essential of the List operations. For comparison, it also shows the most important Queue operations. Two separate lists of tests are created for testing each class of container. In this case, Queue operations only apply to LinkedLists. 
  Each test requires careful thought to ensure that you are producing meaningful results. For example, the "add" test clears the List and then refills it to the specified list size. The call to clear( ) is thus part of the test, and may have an impact on the time, especially for small tests. Although the results here seem fairly reasonable, you could imagine rewriting the test framework so that there is a call to a preparation method (which would, in this case, include the clear( ) call) outside of the timing loop. 
  Note that for each test, you must accurately calculate the number of operations that occur and return that value from test( ), so the timing is correct. 
  The "get" and "set" tests both use the random number generator to perform random accesses to the List. In the output, you can see that, for a List backed by an array and for an ArrayList, these accesses are fast and very consistent regardless of the list size, whereas for     a LinkedList, the access times grow very significantly for larger lists. Clearly, linked lists are not a good choice if you will be performing many random accesses. 
  The "iteradd" test uses an iterator in the middle of the list to insert new elements. For an ArrayList this gets expensive as the list gets bigger, but for a LinkedList it is relatively cheap, and constant regardless of size. This makes sense because an ArrayList must create space and copy all its references forward during an insertion. This becomes expensive as the ArrayList gets bigger. A LinkedList only needs to link in a new element, and doesn’t have to modify the rest of the list, so you expect the cost to be roughly the same regardless of the list size. 
  The "insert" and "remove" tests both use location number 5 as the point of insertion or removal, rather than either end of the List. A LinkedList treats the endpoints of the List specially—this improves the speed when using a LinkedList as a Queue. However, if you add or remove elements in the middle of the list, you include the cost of random access, which we’ve already seen varies with the different List implementations. By performing the insertions and removals at location 5, the cost of the random access should be negligible and we should see only the cost of insertion and removal, but we will not see any specialized optimization for the end of a LinkedList. You can see from the output that the cost of insertion and removal in a LinkedList is quite cheap and doesn’t vary with the list size, but with an ArrayList, insertions especially are very expensive, and the cost increases with list size. 
  From the Queue tests, you can see how quickly a LinkedList can insert and remove elements from the endpoints of the list, which is optimal for Queue behavior. 
  Normally, you can just call Tester.run( ), passing the container and the tests list. Here, however, we must override the initialize( ) method so that the List is cleared and refilled before each test—otherwise the List control over the size of the List would be lost during the various tests. ListTester inherits from Tester and performs this initialization using CountingIntegerList. The run( ) convenience method is also overridden. We’d also like to compare array access to container access (primarily against ArrayList). In the first test in main( ), a special Test object is created using an anonymous inner class. The initialize( ) method is overridden to create a new object each time it is called (ignoring the stored container object, so null is the container argument for this Tester constructor). The new object is created using Generated.array( ) (which was defined in the Arrays chapter) and Arrays.asList( ). Only two of the tests can be performed in this case, because you cannot insert or remove elements when using a List backed by an array, so the List.subList( ) method is used to select the desired tests from the tests list. 
  For random-access get( ) and set( ) operations, a List backed by an array is slightly faster than an ArrayList, but the same operations are dramatically more expensive for a LinkedList because it is not designed for randomaccess operations. 
  Vector should be avoided; it’s only in the library for legacy code support (the only reason it works in this program is because it was adapted to be a List for forward compatibility). 
  The best approach is probably to choose an ArrayList as your default and to change to a LinkedList if you need its extra functionality or you discover performance problems due to many insertions and removals from the middle of the list. If you are working with a fixed- sized group of elements, either use a List backed by an array (as produced by Arrays.asList( )), or if necessary, an actual array. 
  CopyOnWriteArrayList is a special implementation of List used in concurrent programming, and will be discussed in the Concurrency chapter. 
  Exercise 29: (2) Modify ListPerformance.java so that the Lists hold String objects instead of Integers. Use a Generator from the Arrays chapter to create test values. 
  Exercise 30: (3) Compare the performance of Collections.sort( ) between an ArrayList and a LinkedList. 
  Exercise 31: (5) Create a container that encapsulates an array of String, and that only allows adding Strings and getting Strings, so that there are no casting issues during use. If the internal array isn’t big enough for the next add, your container should automatically resize it. In main( ), compare the performance of your container with an ArrayList<String>. 
  Exercise 32: (2) Repeat the previous exercise for a container of int, and compare the performance to an ArrayList<Integer>. In your performance comparison, include the process of incrementing each object in the container. 
  Exercise 33: (5) Create a FastTraversalLinkedList that internally uses a LinkedList for rapid insertions and removals, and an ArrayList for rapid traversals and get( ) operations. Test it by modifying ListPerformance.java. 
Microbenchmarking dangers
  When writing so-called microbenchmarks, you must be careful not to assume too much, and to narrow your tests so that as much as possible they are only timing the items of interest. You must also be careful to ensure that your tests run long enough to produce interesting data, and take into account that some of the Java HotSpot technologies will only kick in when a program runs for a certain time (this is important to consider for short-running programs, as well). 
  Results will be different according to the computer and JVM you are using, so you should run these tests yourself to verify that the results are similar to those shown in this book. You should not be so concerned with absolute numbers as with the performance comparisons between one type of container and another. 
  Also, a profiler may do a better job of performance analysis than you can. Java comes with a profiler (see the supplement at http://MindView.net/Books/BetterJava) and there are third- party profilers available, both free/open-source and commercial. 
  A related example concerns Math.random( ). Does it produce a value from zero to one, inclusive or exclusive of the value "1"? In math lingo, is it (0,1), or [0,1], or (0,1] or [0,1)? (The square bracket means "includes," whereas the parenthesis means "doesn’t include.") A test program might provide the answer: 
  To run the program, you type a command line of either: 
  java RandomBounds lower  or 
  java RandomBounds upper  In both cases, you are forced to break out of the program manually, so it would appear that Math.random( ) never produces either o.o or l.o. But this is where such an experiment can be deceiving. If you consider that there are about 262 different double fractions between o and 1, the likelihood of reaching any one value experimentally might exceed the lifetime of one computer, or even one experimenter. It turns out that 0.0 is included in the output of Math.random( ). Or, in math lingo, it is [0,1). Thus, you must be careful to analyze your experiments and to understand their limitations. 
Choosing between Sets
  Depending on the behavior you desire, you can choose a TreeSet, a HashSet, or a LinkedHashSet. The following test program gives an indication of the performance trade- off between these implementations: 
  The performance of HashSet is generally superior to TreeSet, but especially when adding elements and looking them up, which are the two most important operations. TreeSet exists because it maintains its elements in sorted order, so you use it only when you need a sorted Set. Because of the internal structure necessary to support sorting and because iteration is something you’re more likely to do, iteration is usually faster with a TreeSet than a HashSet. 
  Note that LinkedHashSet is more expensive for insertions than HashSet; this is because of the extra cost of maintaining the linked list along with the hashed container. 
  Exercise 34: (1) Modify SetPerformance.java so that the Sets hold String objects instead of Integers. Use a Generator from the Arrays chapter to create test values. 
  
Choosing between Maps
  This program gives an indication of the trade-off between Map implementations: 
  Insertions for all the Map implementations except for IdentityHashMap get significantly slower as the size of the Map gets large. In general, however, lookup is much cheaper than insertion, which is good because you’ll typically be looking items up much more often than you insert them. 
  Hashtable performance is roughly the same as HashMap. Since HashMap is intended to replace Hashtable, and thus uses the same underlying storage and lookup mechanism (which you will learn about later), this is not too surprising. 
  A TreeMap is generally slower than a HashMap. As with TreeSet, a TreeMap is a way to create an ordered list. The behavior of a tree is such that it’s always in order and doesn’t have to be specially sorted. Once you fill a TreeMap, you can call keySet( ) to get a Set view of the keys, then toArray( ) to produce an array of those keys. You can then use the static method Arrays.binarySearch( ) to rapidly find objects in your sorted array. Of course, this only makes sense if the behavior of a HashMap is unacceptable, since HashMap is designed to rapidly find keys. Also, you can easily create a HashMap from a TreeMap with a single object creation or call to putAll( ). In the end, when you’re using a Map, your first choice should be HashMap, and only if you need a constantly sorted Map will you need TreeMap. 
  LinkedHashMap tends to be slower than HashMap for insertions because it maintains the linked list (to preserve insertion order) in addition to the hashed data structure. Because of this list, iteration is faster. 
  IdentityHashMap has different performance because it uses == rather than equals( ) for comparisons. WeakHashMap is described later in this chapter. 
  Exercise 35: (1) Modify MapPerformance.java to include tests of SlowMap. 
  Exercise 36: (5) Modify SlowMap so that instead of two ArrayLists, it holds a single ArrayList of MapEntry objects. Verify that the modified version works correctly. Using MapPerformance.java, test the speed of your new Map. Now change the put( ) method so that it performs a sort( ) after each pair is entered, and modify get( ) to use Collections.binarySearch( ) to look up the key. Compare the performance of the new version with the old ones. 
  Exercise 37: (2) Modify SimpleHashMap to use ArrayLists instead of LinkedLists. Modify MapPerformance.java to compare the performance of the two implementations. 
  HashMap performance factors  It’s possible to hand-tune a HashMap to increase its performance for your particular application. So that you can understand performance issues when tuning a HashMap, some terminology is necessary: 
  Capacity: The number of buckets in the table. 
  Initial capacity: The number of buckets when the table is created. HashMap and HashSet have constructors that allow you to specify the initial capacity. 
  Size: The number of entries currently in the table. 
  Load factor: Size/capacity. A load factor of o is an empty table, 0.5 is a half-full table, etc. A lightly loaded table will have few collisions and so is optimal for insertions and lookups (but will slow down the process of traversing with an iterator). HashMap and HashSet have constructors that allow you to specify the load factor, which means that when this load factor is reached, the container will automatically increase the capacity (the number of buckets) by roughly doubling it and will redistribute the existing objects into the new set of buckets (this is called rehashing). 
  The default load factor used by HashMap is 0.75 (it doesn’t rehash until the table is three- fourths full). This seems to be a good trade-off between time and space costs. A higher load factor decreases the space required by the table but increases the lookup cost, which is important because lookup is what you do most of the time (including both get( ) and put( )). 
  If you know that you’ll be storing many entries in a HashMap, creating it with an 11 appropriately large initial capacity will prevent the overhead of automatic rehashing. 
  Exercise 38: (3) Look up the HashMap class in the JDK documentation. Create a HashMap, fill it with elements, and determine the load factor. Test the lookup speed with this map, then attempt to increase the speed by making a new HashMap with a larger initial capacity and copying the old map into the new one, then run your lookup speed test again on the new map. 
  table size and load factor) into our APIs. The client should perhaps tell us the maximum expected size of a collection, and we should take it from there. Clients can easily do more harm than good by choosing values for these parameters. As an extreme example, consider Vector’s capacitylncrement. No one should ever set this, and we shouldn’t have provided it. If you set it to any nonzero value, the asymptotic cost of a sequence of appends goes from linear to quadratic. In other words, it destroys your performance. Over time, we’re beginning to wise up about this sort of thing. If you look at IdentityHashMap, you’ll see that it has no low-level tuning parameters." 
  Exercise 39: (6) Add a private rehash( ) method to SimpleHashMap that is invoked when the load factor exceeds 0.75. During rehashing, double the number of buckets, then search for the first prime number greater than that to determine the new number of buckets. 
