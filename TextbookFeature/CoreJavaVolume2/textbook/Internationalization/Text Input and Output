  As you know, the Java programming language itself is fully Unicode-based. 
  However, Windows and Mac OS X still support legacy character encodings such as Windows-1252 or Mac Roman in Western European countries, or Big5 in Taiwan. Therefore, communicating with your users through text is not as simple as   From the Library of Hristo Dimov Hristov   7.7 Text Input and Output   405   it should be. The following sections discuss the complications that you may encounter. 
  7.7.1 Text Files Nowadays, it is best to use UTF-8 for saving and loading text files. But you may need to work with legacy files. If you know the expected character encoding, you can specify it when writing or reading text files: PrintWriter out = new PrintWriter(filename, "Windows-1252"); 
  For a guess of the best encoding to use, get the “platform encoding” by calling Charset platformEncoding = Charset.defaultCharset(); 
  7.7.2 Line Endings This isn’t an issue of locales but of platforms. On Windows, text files are expected to use \r\n at the end of each line, where UNIX-based systems only require a \n character. Nowadays, most Windows programs can deal with just a \n. The notable exception is Notepad. If it is important to you that users can double-click on a text file that your application produces and view it in Notepad, make sure that the text file has proper line endings. 
  Any line written with the println method will be properly terminated. The only problem is if you print strings that contain \n characters. They are not automatically modified to the platform line ending. 
  Instead of using \n in strings, you can use printf and the %n format specifier to produce platform-dependent line endings. For example, out.printf("Hello%nWorld%n"); 
  produces Hello\r\nWorld\r\n   on Windows and Hello\nWorld\n   everywhere else. 
  7.7.3 The Console If you write programs that communicate with the user through System.in/System.out or System.console(), you have to face the possibility that the console may use a character encoding that is different from the platform encoding reported by   From the Library of Hristo Dimov Hristov   406   Chapter 7   Internationalization   Charset.defaultCharset(). This is particularly noticeable when working with the cmd shell on Windows. In the US version, the command shell uses the archaic IBM437   encoding that originated with IBM personal computers in 1982. There is no official API for revealing that information. The Charset.defaultCharset() method will return the Windows-1252 character set, which is quite different. For example, the euro symbol € is present in Windows-1252 but not in IBM437. When you call System.out.println("100 €"); 
  the console will display 100 ? 
  You can advise your users to switch the character encoding of the console. In Windows, that is achieved with the chcp command. For example, chcp 1252   changes the console to the Windows-1252 code page. 
  Ideally, of course, your users should switch the console to UTF-8. In Windows, the command is chcp 65001   Unfortunately, that is not enough to make Java use UTF-8 in the console. It is also necessary to set the platform encoding with the unofficial file.encoding system property: java -Dfile.encoding=UTF-8 MyProg   7.7.4 Log Files When log messages from the java.util.logging library are sent to the console, they are written with the console encoding. You saw how to control that in the preceding section. However, log messages in a file use a FileHandler which, by default, uses the platform encoding. 
  To change the encoding to UTF-8, you need to change the log manager settings. 
  In the logging configuration file, set java.util.logging.FileHandler.encoding=UTF-8   7.7.5 The UTF-8 Byte Order Mark As already mentioned, it is a good idea to use UTF-8 for text files when you can. 
  If your application has to read UTF-8 text files that were created by other programs, you run into another potential problem. It is perfectly legal to add a “byte order mark” character U+FEFF as the first character of a file. In the UTF-16   From the Library of Hristo Dimov Hristov   7.7 Text Input and Output   407   encoding, where each code unit is a two-byte quantity, the byte order mark tells a reader whether the file uses “big-endian” or “little-endian” byte ordering. UTF-8 is a single-byte encoding, so there is no need for specifying a byte ordering. 
  But if a file starts with bytes 0xEF 0xBB 0xBF (the UTF-8 encoding of U+FEFF), that is a strong indication that it uses UTF-8. For that reason, the Unicode standard encourages this practice. Any reader is supposed to discard an initial byte order mark. 
  There is just one fly in the ointment. The Oracle Java implementation stubbornly refuses to follow the Unicode standard, citing potential compatibility issues. That means that you, the programmer, must do what the platform won’t do. When you read a text file and encounter a U+FEFF at the beginning, ignore it. 
  CAUTION: Unfortunately, the JDK implementors do not follow this advice. When you pass the javac compiler a valid UTF-8 source file that starts with a byte order mark, compilation fails with an error message “illegal character: \65279”. 
  7.7.6 Character Encoding of Source Files You, the programmer, will need to communicate with the Java compiler—and you do that with tools on your local system. For example, you can use the Chinese version of Notepad to write your Java source code files. The resulting source code files are not portable because they use the local character encoding (GB or Big5, depending on which Chinese operating system you use). Only the compiled class files are portable—they will automatically use the “modified UTF-8” encoding for identifiers and strings. That means that when a program is compiling and running, three character encodings are involved: • Source files: platform encoding • Class files: modified UTF-8 • Virtual machine: UTF-16 (See Chapter 2 for a definition of the modified UTF-8 and UTF-16 formats.) TIP: You can specify the character encoding of your source files with the -encoding flag, for example, javac -encoding UTF-8 Myfile.java   To make your source files portable, restrict yourself to using the plain ASCII encoding. That is, change all non-ASCII characters to their equivalent Unicode escapes. For example, instead of using the string "Häuser", use "H\u0084user". The JDK   From the Library of Hristo Dimov Hristov   408   Chapter 7   Internationalization   contains a utility, native2ascii, that you can use to convert the native character encoding to plain ASCII. This utility simply replaces every non-ASCII character in the input with a \u followed by the four hex digits of the Unicode value. To use the native2ascii program, provide the input and output file names. 
  native2ascii Myfile.java Myfile.temp   You can convert the other way with the -reverse option: native2ascii -reverse Myfile.temp Myfile.java   You can specify another encoding with the -encoding option. 
